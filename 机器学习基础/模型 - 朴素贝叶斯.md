# 朴素贝叶斯
tags: machine-learning

---

[TOC]

## 1. 先验概率与后验概率

### 1. 条件概率

$$
P(X|Y) =  \frac{P(X,Y)}{P(Y)}
$$

- $P(X|Y)$含义： 表示 y 发生的条件下 x 发生的概率。

### 2. 先验概率

- 含义： **表示事件发生前的预判概率。**这个可以是基于历史数据统计，也可以由背景常识得出，也可以是主观观点得出。
- 一般都是单独事件发生的概率，如 P(A)

### 3. 后验概率

- 基于先验概率求得的**反向条件概率**，形式上与条件概率相同（若 `P(X|Y)` 为正向，则 `P(Y|X)` 为反向）

## 2. 贝叶斯公式

贝叶斯公式如下：
$$
P(Y|X) = \frac{P(X|Y) P(Y)}{P(X)}
$$
我们先来推导一下贝叶斯公式的由来。

首先，我们知道条件概率有：
$$
P(Y|X) = \frac{P(X,Y)}{P(X)}   \\\
P(X|Y) = \frac{P(X,Y) }{P(Y)}
$$
由此我们可以得出：
$$
P(Y, X) = P(X, Y) = P(Y|X)P(X) = P(X|Y) P(Y)
$$
$$
P(Y|X) = \frac{P(X|Y) P(Y)}{P(X)}
$$
> - P(Y) 叫做先验概率，意思是事件X发生之前，我们对事件Y发生的一个概率的判断
> - P(Y|X) 叫做后验概率，意思是时间X发生之后，我们对事件Y发生的一个概率的重新评估
> - P(Y,X) 叫做联合概率， 意思是事件X与事件Y同时发生的概率。

### 3. 条件独立假设

$$
P(x|c) = p(x_1, x_2,  \cdots x_n | c) = p(x_1 | c) * P(x_2 | c) \cdots P(x_n|c)
$$

条件独立假设与朴素贝叶斯之间的关系可以通过一句话描述： **加上条件独立假设的贝叶斯方法就是朴素贝叶斯方法**。

注意： **朴素贝叶斯没有考虑到词之间的顺序，也就是说“武松打死老虎” 与 “老虎打死武松” 最终我们得出的概率是一样的。 **

## 从机器学习视角理解朴素贝叶斯

在机器学习中，我们可以将X理解为“具有某特征”， 而Y理解为“类别标签”，于是有：
$$
P("属于某类“ \, \, | \, \, "具有某特征" ) = \frac{P("具有某特征" | "属于某类") P("属于某类")}{P("具有某特征" )}
$$

垃圾邮件分类算是一个比较经典的问题了，我们这里就以此为例：

问题描述：

- 判断 P("垃圾邮件" | "具有某特征") 的概率（也就是说判断一封邮件是否为垃圾邮件的概率）

- 我们这里给出一封邮件，判断其是否为垃圾邮件：“ 我公司...。”


问题解决：

> - 我们要求取的概率为：
>   $$
>   P("垃圾邮件”| “我公司...” )
>   $$
>
> - 第一步：首先，我们是要分词，分词之后结果为：
>   $$
>   P("垃圾邮件”| (“我" , "公司" , "...")  )   \\\
>   = \frac{P((“我" , "公司" ,"...")  | "垃圾邮件" )  P("垃圾邮件")}{P( (“我" , "公司" , "可", "...")  )}
>   $$
>
>

根据**条件独立假设**
$$
P((“我" , "公司" , "可", "...")  |S =  "垃圾邮件" ) \\\
= P("我" | S)  × P("公司" | S) × P("可" | S) × P("..." | S)
$$


其中有：
$$
P("我" | S) = \frac{垃圾邮件中“我” 出现的次数} {垃圾邮件中所有词出现的次数}
$$

## 朴素贝叶斯中的三种模型

### 1.  多项式模型

多项式模型适用于离散特征情况，在文本领域应用广泛， 其基本思想是：我们将重复的词语视为其出现多次。

比如：“我公司可办理正规发票17%增值税发票点数优惠。” 中发表出现了两次，那么则有：
$$
P( " 代开“， ”发票“， ”发票“， ”我“ | S) = \\P("代开" | S) P( ”发票“ | S)   P( ”发票“ | S) P("我" | S)
$$
我们看到，我们有两个发票出现，所以我们乘了两个 P("发票" | S)。

### 2. 高斯模型

https://blog.csdn.net/u012162613/article/details/48323777

http://www.letiantian.me/2014-10-12-three-models-of-naive-nayes/

高斯模型适合**连续特征情况**， 我们先给出高斯公式：
$$
P(x_{i}|y_{k}) = \frac{1}{\sqrt{2\pi\sigma_{y_{k}}^{2}}}exp( -\frac{(x_{i}-\mu_{y_{k}})^2}  {2\sigma_{y_{k}}^{2}}   )
$$


### 3. 伯努利模型

> 伯努利模型适用于离散特征情况，它将重复的词语都视为只出现一次。
> $$
> P( " 代开“， ”发票“， ”发票“， ”我“ | S) = P("代开" | S)   P( ”发票“ | S) P("我" | S)
> $$
> 我们看到，”发票“出现了两次，但是我们只将其算作一次。

---

## QA

### 1. 朴素贝叶斯为何朴素？

朴素贝叶斯的朴素性体现在该算法基于一个简单的假设： **所有的变量都是相互独立的**，用贝叶斯公式表达如下：
$$
P(Y|X_1, X_2) = \frac{P(X_1|Y) P(X_2|Y) P(Y)}{P(X_1)P(X_2)}
$$
**而在很多情况下，所有变量几乎不可能满足两两之间的条件。**

### 2. 朴素贝叶斯分类中某个类别的概率为0怎么办？

**问题：** 如下，A1,A2,A3是三个特征，Y是分类结果。

|  A1  |  A2  |  A3  |  Y   |
| :--: | :--: | :--: | :--: |
|  1   |  1   |  0   |  1   |
|  0   |  1   |  1   |  1   |
|  1   |  0   |  1   |  0   |
|  0   |  1   |  0   |  0   |
|  0   |  0   |  1   |  0   |

```
P(Y=0) = 3/5
P(Y=1) = 2/5
P(Y=0|A1=1,A2=0,A3=0) = 3/5 * 1/3 * 2/3 * 1/3 = 2/45
P(Y=1|A1=1,A2=0,A3=0) = 2/5 * 1/2 * 1/4 * 1/2 = 1/40
```

答案是 **拉普拉斯平滑**。

### 3. 朴素贝叶斯的要求是什么？

- 贝叶斯定理
- 特征条件独立假设

### 4. 朴素贝叶斯的优缺点？

- 优点： 对小规模数据表现很好，适合多分类任务，适合增量式训练。
- 缺点：对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）。

### 5. 朴素贝叶斯与 LR 区别？

-  朴素贝叶斯是生成模型，根据已有样本进行贝叶斯估计学习出先验概率 P(Y) 和条件概率 P(X|Y)，进而求出联合分布概率 P(XY)，最后利用贝叶斯定理求解P(Y|X)， 而LR是判别模型，根据极大化对数似然函数直接求出条件概率 P(Y|X)
- 朴素贝叶斯是基于很强的**条件独立假设**（在已知分类Y的条件下，各个特征变量取值是相互独立的），而 LR 则对此没有要求
- 朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。